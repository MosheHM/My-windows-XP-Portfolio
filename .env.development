# Development Environment Configuration

# LLM Service Configuration
LLM_MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
LLM_MAX_LENGTH=2048
LLM_TEMPERATURE=0.7
RAG_DATA_FILE=/app/data/resume_data.json

# File Service Configuration
STORAGE_PATH=/data/files
METADATA_PATH=/data/metadata
MAX_FILE_SIZE=104857600

# Client Configuration (accessed via nginx gateway)
VITE_LLM_SERVICE_URL=/api/llm
VITE_FILE_SERVICE_URL=/api/files

# Nginx Gateway
NGINX_PORT=80
